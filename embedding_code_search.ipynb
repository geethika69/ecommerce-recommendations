{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBE8QeCw57iAHIyI+uoAHU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9ea6f40ae593442193ba9f693aa29eeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22d50259619845e98c3c1c768ab06de9",
              "IPY_MODEL_5a9ab1ca99454a0ca9977ba7c638d15a",
              "IPY_MODEL_6029fd28aa574ba693962f7f75c4f328"
            ],
            "layout": "IPY_MODEL_eb398687d4d244ea85af4370b64b8296"
          }
        },
        "22d50259619845e98c3c1c768ab06de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84adc87e76204c448e0eda19ce058adb",
            "placeholder": "​",
            "style": "IPY_MODEL_d9a03b6879df494fbd8d71c3a362c591",
            "value": "Computing widget examples:   0%"
          }
        },
        "5a9ab1ca99454a0ca9977ba7c638d15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_853ab655f22b4544961000f75852236c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70b746840772479d962d6abf68d29e6c",
            "value": 1
          }
        },
        "6029fd28aa574ba693962f7f75c4f328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a293005086c34bccb66e39341ba59db7",
            "placeholder": "​",
            "style": "IPY_MODEL_2a6a7840325e4b13b0d93fb0b766b6a0",
            "value": " 0/1 [00:00&lt;?, ?example/s]"
          }
        },
        "eb398687d4d244ea85af4370b64b8296": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "84adc87e76204c448e0eda19ce058adb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9a03b6879df494fbd8d71c3a362c591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "853ab655f22b4544961000f75852236c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70b746840772479d962d6abf68d29e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a293005086c34bccb66e39341ba59db7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a6a7840325e4b13b0d93fb0b766b6a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geethika69/ecommerce-recommendations/blob/main/embedding_code_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-CW-YeNr06g"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install sentence-transformers usearch torch datasets matplotlib scikit-learn numpy\n",
        "\n",
        "# Import necessary libraries (will be used across cells)\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from usearch.index import Index\n",
        "from torch.utils.data import DataLoader\n",
        "from sentence_transformers import losses, InputExample\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# search_engine.py\n",
        "class CodeSearchEngine:\n",
        "    def __init__(self, model_name='sentence-transformers/all-MiniLM-L6-v2', metric='cos', dimensions=384):\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        self.index = Index(ndim=dimensions, metric=metric, dtype=np.float32)\n",
        "        self.doc_ids = []\n",
        "\n",
        "    def index_documents(self, documents):\n",
        "        \"\"\"Index a list of code snippet documents.\"\"\"\n",
        "        embeddings = self.model.encode(documents, normalize_embeddings=True, show_progress_bar=True)\n",
        "        for i, emb in enumerate(embeddings):\n",
        "            self.index.add(i, emb)\n",
        "            self.doc_ids.append(documents[i])  # Store original docs\n",
        "\n",
        "    def search(self, query, top_k=10):\n",
        "        \"\"\"Search for top-k similar code snippets.\"\"\"\n",
        "        query_emb = self.model.encode([query], normalize_embeddings=True)\n",
        "        matches = self.index.search(query_emb[0], top_k)\n",
        "        results = [(self.doc_ids[match.id], match.score) for match in matches]\n",
        "        return results"
      ],
      "metadata": {
        "id": "IPCEFOINsxVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation.py\n",
        "import numpy as np\n",
        "from scipy.stats import rankdata\n",
        "\n",
        "def recall_at_k(relevant, predicted, k=10):\n",
        "    \"\"\"Recall@K: Fraction of relevant in top-K.\"\"\"\n",
        "    top_k = predicted[:k]\n",
        "    return len(set(relevant) & set(top_k)) / len(relevant) if relevant else 0\n",
        "\n",
        "def mrr_at_k(relevant, predicted, k=10):\n",
        "    \"\"\"MRR@K: Mean reciprocal rank in top-K.\"\"\"\n",
        "    top_k = predicted[:k]\n",
        "    for rank, item in enumerate(top_k, 1):\n",
        "        if item in relevant:\n",
        "            return 1 / rank\n",
        "    return 0\n",
        "\n",
        "def ndcg_at_k(relevant, predicted, k=10):\n",
        "    \"\"\"nDCG@K (binary relevance).\"\"\"\n",
        "    top_k = predicted[:k]\n",
        "    rel = [1 if i in relevant else 0 for i in top_k]\n",
        "    dcg = sum(r / np.log2(i + 1) for i, r in enumerate(rel))\n",
        "    idcg = sum(1 / np.log2(i + 1) for i in range(min(k, len(relevant))))\n",
        "    return dcg / idcg if idcg > 0 else 0\n",
        "\n",
        "def evaluate_search(engine, test_queries, ground_truth, k=10):\n",
        "    \"\"\"Evaluate on list of (query, relevant_doc_ids).\"\"\"\n",
        "    recalls, mrrs, ndcgs = [], [], []\n",
        "    for query, rel_ids in zip(test_queries, ground_truth):\n",
        "        results = engine.search(query, k)\n",
        "        predicted = [doc for doc, _ in results]  # Assume doc_ids match\n",
        "        recalls.append(recall_at_k(rel_ids, predicted, k))\n",
        "        mrrs.append(mrr_at_k(rel_ids, predicted, k))\n",
        "        ndcgs.append(ndcg_at_k(rel_ids, predicted, k))\n",
        "    return np.mean(recalls), np.mean(mrrs), np.mean(ndcgs)"
      ],
      "metadata": {
        "id": "xgm1kn1ks6Nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation.py\n",
        "import numpy as np\n",
        "from scipy.stats import rankdata\n",
        "\n",
        "def recall_at_k(relevant, predicted, k=10):\n",
        "    \"\"\"Recall@K: Fraction of relevant in top-K.\"\"\"\n",
        "    top_k = predicted[:k]\n",
        "    return len(set(relevant) & set(top_k)) / len(relevant) if relevant else 0\n",
        "\n",
        "def mrr_at_k(relevant, predicted, k=10):\n",
        "    \"\"\"MRR@K: Mean reciprocal rank in top-K.\"\"\"\n",
        "    top_k = predicted[:k]\n",
        "    for rank, item in enumerate(top_k, 1):\n",
        "        if item in relevant:\n",
        "            return 1 / rank\n",
        "    return 0\n",
        "\n",
        "def ndcg_at_k(relevant, predicted, k=10):\n",
        "    \"\"\"nDCG@K (binary relevance).\"\"\"\n",
        "    top_k = predicted[:k]\n",
        "    rel = [1 if i in relevant else 0 for i in top_k]\n",
        "    dcg = sum(r / np.log2(i + 1) for i, r in enumerate(rel))\n",
        "    idcg = sum(1 / np.log2(i + 1) for i in range(min(k, len(relevant))))\n",
        "    return dcg / idcg if idcg > 0 else 0\n",
        "\n",
        "def evaluate_search(engine, test_queries, ground_truth, k=10):\n",
        "    \"\"\"Evaluate on list of (query, relevant_doc_ids).\"\"\"\n",
        "    recalls, mrrs, ndcgs = [], [], []\n",
        "    for query, rel_ids in zip(test_queries, ground_truth):\n",
        "        results = engine.search(query, k)\n",
        "        predicted = [doc for doc, _ in results]  # Assume doc_ids match\n",
        "        recalls.append(recall_at_k(rel_ids, predicted, k))\n",
        "        mrrs.append(mrr_at_k(rel_ids, predicted, k))\n",
        "        ndcgs.append(ndcg_at_k(rel_ids, predicted, k))\n",
        "    return np.mean(recalls), np.mean(mrrs), np.mean(ndcgs)"
      ],
      "metadata": {
        "id": "marLoH80s9HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual Dataset Loading\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the uploaded dataset\n",
        "dataset = load_dataset(\"json\", data_files=\"/content/gpt4o_augment_query_code_pairs.json\", split=\"train\")\n",
        "\n",
        "# Inspect the dataset to confirm structure\n",
        "print(dataset)\n",
        "print(\"Columns available:\", dataset.column_names)\n",
        "\n",
        "# Prepare training examples (assuming 'query' and 'code' fields)\n",
        "train_examples = [InputExample(texts=[q, c], label=1.0) for q, c in zip(dataset['query'], dataset['code'])]\n",
        "print(f\"Number of training examples: {len(train_examples)}\")"
      ],
      "metadata": {
        "id": "PO3lXVFBxDpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fine_tune.py\n",
        "from google.colab import drive\n",
        "from sentence_transformers import SentenceTransformer, losses, InputExample\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Disable W&B logging\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Mount Google Drive (skip if already mounted)\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "except ValueError:\n",
        "    print(\"Drive already mounted; proceeding without remount.\")\n",
        "\n",
        "# Use the manually loaded dataset (assume loaded from previous cell)\n",
        "train_examples = [InputExample(texts=[q, c], label=1.0) for q, c in zip(dataset['query'], dataset['code'])]\n",
        "\n",
        "# Initialize and fine-tune model\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
        "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
        "\n",
        "# Fine-tune with loss tracking\n",
        "loss_history = []\n",
        "model.fit(\n",
        "    train_objectives=[(train_dataloader, train_loss)],\n",
        "    epochs=1,\n",
        "    warmup_steps=100,\n",
        "    output_path='/content/drive/MyDrive/fine_tuned_cosqa',\n",
        "    callback=lambda m, l: loss_history.append(l.item()) if l.item() is not None else None\n",
        ")\n",
        "\n",
        "# Plot loss\n",
        "plt.plot(loss_history)\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Mean Loss During Fine-Tuning')\n",
        "plt.show()\n",
        "\n",
        "# Save model to Google Drive\n",
        "model.save('/content/drive/MyDrive/fine_tuned_cosqa')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182,
          "referenced_widgets": [
            "9ea6f40ae593442193ba9f693aa29eeb",
            "22d50259619845e98c3c1c768ab06de9",
            "5a9ab1ca99454a0ca9977ba7c638d15a",
            "6029fd28aa574ba693962f7f75c4f328",
            "eb398687d4d244ea85af4370b64b8296",
            "84adc87e76204c448e0eda19ce058adb",
            "d9a03b6879df494fbd8d71c3a362c591",
            "853ab655f22b4544961000f75852236c",
            "70b746840772479d962d6abf68d29e6c",
            "a293005086c34bccb66e39341ba59db7",
            "2a6a7840325e4b13b0d93fb0b766b6a0"
          ]
        },
        "id": "3nqJvGfzzDfq",
        "outputId": "67b164c4-2bcc-40eb-bf36-5f80db44708b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ea6f40ae593442193ba9f693aa29eeb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='31' max='6806' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  31/6806 03:30 < 13:41:26, 0.14 it/s, Epoch 0.00/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}